{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "251bddb7-4b85-466d-95f3-f904b9ccdd6e",
   "metadata": {},
   "source": [
    "# üß™ Test avec le mod√®le pr√©-entra√Æn√© tel quel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "16899ed2-b3fc-4711-a3fb-dabd093a1b68",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Texte: This movie was fantastic! I really enjoyed it.\n",
      "Sentiment pr√©dit: Positif\n",
      "\n",
      "Texte: I hated this film, it was so bad.\n",
      "Sentiment pr√©dit: Positif\n",
      "\n",
      "Texte: The plot was interesting, but the acting was terrible.\n",
      "Sentiment pr√©dit: Positif\n",
      "\n",
      "Texte: An absolute masterpiece, one of the best movies I have ever seen.\n",
      "Sentiment pr√©dit: Positif\n",
      "\n",
      "Texte: It was okay, nothing special but not the worst either.\n",
      "Sentiment pr√©dit: Positif\n",
      "\n",
      "Texte: I fell asleep halfway through, it was so boring.\n",
      "Sentiment pr√©dit: Positif\n",
      "\n",
      "Texte: Amazing cinematography and great performances from the cast.\n",
      "Sentiment pr√©dit: Positif\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "import torch\n",
    "\n",
    "# Charger le mod√®le DistilBERT de base (non fine-tun√©)\n",
    "model_name = \"distilbert-base-uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "# Ajouter une t√™te de classification (non entra√Æn√©e)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=2)\n",
    "\n",
    "def predict_sentiment(text):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    logits = outputs.logits\n",
    "    predicted_class = torch.argmax(logits, dim=1).item()\n",
    "    return \"Positif\" if predicted_class == 1 else \"N√©gatif\"\n",
    "\n",
    "# Tester avec des phrases\n",
    "examples = [\n",
    "    \"This movie was fantastic! I really enjoyed it.\",\n",
    "    \"I hated this film, it was so bad.\",\n",
    "    \"The plot was interesting, but the acting was terrible.\",\n",
    "    \"An absolute masterpiece, one of the best movies I have ever seen.\",\n",
    "    \"It was okay, nothing special but not the worst either.\",\n",
    "    \"I fell asleep halfway through, it was so boring.\",\n",
    "    \"Amazing cinematography and great performances from the cast.\"\n",
    "]\n",
    "for sentence in examples:\n",
    "    print(f\"Texte: {sentence}\")\n",
    "    print(f\"Sentiment pr√©dit: {predict_sentiment(sentence)}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdb0c97b-4f34-41e7-b04a-3db2a609492c",
   "metadata": {},
   "source": [
    "# üìÇ Chargement du jeu de donn√©es IMDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b4c29075-f762-4364-a162-6aa0e0672826",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exemple index 0 :\n",
      "Texte : I found this to be a so-so romance/drama that has a nice ending and a generally nice feel to it. It's not a Hallmark Hall Of Fame-type family film with sleeping-before-marriage considered \"normal\" behavior but considering it stars Jane Fonda and Robert De Niro, I would have expected a lot rougher movie, at least language-wise. <br /><br />The most memorable part of the film is the portrayal of how difficult it must be to learn how to read and write when you are already an adult. That's the big theme of the movie and it involves some touching scenes but, to be honest, the film isn't that memorable.<br /><br />It's still a fairly mild, nice tale that I would be happy to recommend.\n",
      "Label : Positif\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "import random\n",
    "\n",
    "# Charge automatiquement le dataset IMDB\n",
    "dataset = load_dataset(\"imdb\")\n",
    "\n",
    "# S√©lectionner 250 exemples positifs et 250 n√©gatifs pour l'entra√Ænement\n",
    "positive_samples = [ex for ex in dataset[\"train\"] if ex[\"label\"] == 1][:250]\n",
    "negative_samples = [ex for ex in dataset[\"train\"] if ex[\"label\"] == 0][:250]\n",
    "small_train_dataset = positive_samples + negative_samples\n",
    "\n",
    "# M√©langer les donn√©es pour √©viter les biais d'ordre\n",
    "random.shuffle(small_train_dataset)\n",
    "\n",
    "# R√©duire aussi la taille du dataset test en √©quilibrant\n",
    "positive_test_samples = [ex for ex in dataset[\"test\"] if ex[\"label\"] == 1][:50]\n",
    "negative_test_samples = [ex for ex in dataset[\"test\"] if ex[\"label\"] == 0][:50]\n",
    "small_test_dataset = positive_test_samples + negative_test_samples\n",
    "\n",
    "# Affiche un √©chantillon\n",
    "def print_sample(index=0):\n",
    "    print(f\"Exemple index {index} :\")\n",
    "    print(\"Texte :\", small_train_dataset[index][\"text\"])\n",
    "    print(\"Label :\", \"Positif\" if small_train_dataset[index][\"label\"] == 1 else \"N√©gatif\")\n",
    "\n",
    "# Affiche un √©chantillon du jeu de donn√©es d'entra√Ænement\n",
    "print_sample()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6706854e-efaf-4ee9-a864-2d968c6df03a",
   "metadata": {},
   "source": [
    "# üîß Pr√©-traitement des donn√©es"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7017bd09-0463-4b20-b98f-2604869bba34",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "from datasets import Dataset\n",
    "\n",
    "# Charge le tokenizer de _DistilBERT_\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
    "\n",
    "# Tokenisation des sous-ensembles\n",
    "tokenized_train = tokenizer([ex['text'] for ex in small_train_dataset], padding=True, truncation=True, max_length=512)\n",
    "tokenized_test = tokenizer([ex['text'] for ex in small_test_dataset], padding=True, truncation=True, max_length=512)\n",
    "\n",
    "\n",
    "# Ajouter les labels aux datasets tokenis√©s\n",
    "tokenized_train['labels'] = [ex['label'] for ex in small_train_dataset]\n",
    "tokenized_test['labels'] = [ex['label'] for ex in small_test_dataset]\n",
    "\n",
    "# Convertir en objets Dataset\n",
    "tokenized_train_dataset = Dataset.from_dict(tokenized_train)\n",
    "tokenized_test_dataset = Dataset.from_dict(tokenized_test)\n",
    "\n",
    "# Cr√©ation d'un dictionnaire pour garder la structure initiale\n",
    "tokenized_datasets = {\n",
    "    \"train\": tokenized_train_dataset,\n",
    "    \"test\": tokenized_test_dataset\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63ba8d0a-4a06-435d-a7ff-6536fcad7b02",
   "metadata": {},
   "source": [
    "# üõ†Ô∏è Pr√©paration des donn√©es pour l'entra√Ænement"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac8950f2-8019-49d8-a2f0-83b7e8c53d4f",
   "metadata": {},
   "source": [
    "## Utilisation de DataCollatorWithPadding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5239f5ed-857b-497d-b683-df9069b50ec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorWithPadding\n",
    "\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer, return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfc4ca92-1ca3-4302-b405-d728872f89a6",
   "metadata": {},
   "source": [
    "# ü§ñ Chargement du mod√®le pr√©-entra√Æn√©"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5343be38-e4fc-49fd-88e8-ac3ee2505a7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"distilbert-base-uncased\", num_labels=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78e594c8-87d7-4c15-86de-3066617614ce",
   "metadata": {},
   "source": [
    "# ‚öôÔ∏è D√©finition des param√®tres d'entra√Ænement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bae69a79-7809-4b8d-83cc-95bf1ebd09c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments, Trainer\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    learning_rate=5e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=2,\n",
    "    weight_decay=0.01,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_datasets[\"train\"],\n",
    "    eval_dataset=tokenized_datasets[\"test\"],\n",
    "    processing_class=tokenizer,\n",
    "    data_collator=data_collator,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4152ec9-6855-4655-bcdf-36f63efee60f",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b4860c6-8165-49a6-b2b9-1d0af074423d",
   "metadata": {},
   "source": [
    "# üìä √âvaluation sur les donn√©es de test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fffcf31-79d3-45c1-91df-c96c66b94a37",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = trainer.evaluate()\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42e50ac7-a996-42d2-a398-2b375a7862f3",
   "metadata": {},
   "source": [
    "# üë©‚Äçüî¨Test du mod√®le sur des exemples personnalis√©s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdd80543-b030-4cbb-bd27-12f278ab5670",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def predict_sentiment(text):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    logits = outputs.logits\n",
    "    predicted_class = torch.argmax(logits, dim=1).item()\n",
    "    return \"Positif\" if predicted_class == 1 else \"N√©gatif\"\n",
    "\n",
    "# Test avec quelques phrases\n",
    "examples = [\n",
    "    \"This movie was fantastic! I really enjoyed it.\",\n",
    "    \"I hated this film, it was so bad.\",\n",
    "    \"The plot was interesting, but the acting was terrible.\",\n",
    "    \"An absolute masterpiece, one of the best movies I have ever seen.\",\n",
    "    \"It was okay, nothing special but not the worst either.\",\n",
    "    \"I fell asleep halfway through, it was so boring.\",\n",
    "    \"Amazing cinematography and great performances from the cast.\",\n",
    "    \"The story was confusing and hard to follow.\",\n",
    "    \"A complete waste of time, I regret watching it.\",\n",
    "    \"I laughed so much! This comedy was hilarious.\",\n",
    "    \"The soundtrack was beautiful, but the script was weak.\",\n",
    "    \"This horror movie actually scared me, great job!\",\n",
    "    \"Way too predictable, I saw every twist coming.\",\n",
    "    \"I wouldn't recommend this to anyone.\",\n",
    "    \"Surprisingly good! I didn't expect to like it this much.\",\n",
    "    \"The ending was disappointing, but the rest was solid.\",\n",
    "    \"One of the worst movies of the year.\",\n",
    "    \"A fresh and original take on the genre.\",\n",
    "    \"The characters felt real and relatable.\",\n",
    "    \"It tried too hard to be deep but ended up being pretentious.\"\n",
    "]\n",
    "for sentence in examples:\n",
    "    print(f\"Texte: {sentence}\")\n",
    "    print(f\"Sentiment pr√©dit: {predict_sentiment(sentence)}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3346fc79-f8c8-448a-92d9-b79d3e76dd14",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
